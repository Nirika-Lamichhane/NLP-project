{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5709744",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, GlobalMaxPooling1D, Bidirectional, LSTM, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c888bef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sample:\n",
      "                                             comment      aspect  sentiment\n",
      "0                                           sentence      aspect  sentiment\n",
      "1  सिंहदरबार जलेको दृश्य देख्दा धेरै पीडा हुन्छ अ...      policy   negative\n",
      "2  राजनीतिक दलको इच्छा बुझ्ने प्रयास कहिल्यै भएको...      policy   negative\n",
      "3  मान्छेको बोलीमा शक्ति हुन्छ ख्याल गरेर बोल्नुपर्छ      policy    neutral\n",
      "4  बालेन र सुदन गुरुङ विदेशी दलालको एजेन्डा बोकेक...  governance   negative\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# dataset_path = '/content/training_dataset.csv'\n",
    "dataset_path = 'dataset/training_dataset.csv'\n",
    "df = pd.read_csv(dataset_path, header=None, names=[\"comment\",\"target\",\"aspect\",\"sentiment\"])\n",
    "\n",
    "df['aspect'] = df['aspect'].astype(str).str.lower()\n",
    "df['sentiment'] = df['sentiment'].astype(str).str.lower()\n",
    "# Drop unused column\n",
    "df = df.drop(columns=[\"target\"])\n",
    "\n",
    "print(\"Dataset sample:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efc053b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset shape: (4129, 3)\n"
     ]
    }
   ],
   "source": [
    "valid_aspects = [\"policy\", \"governance\", \"service\", \"economy\", \"corruption\"]\n",
    "valid_sentiments = [\"positive\", \"neutral\", \"negative\"]\n",
    "\n",
    "df = df[df['aspect'].isin(valid_aspects)]\n",
    "df = df[df['sentiment'].isin(valid_sentiments)]\n",
    "\n",
    "df = df[df['comment'].apply(lambda x: 3 <= len(str(x).split()) <= 11)]\n",
    "\n",
    "print(\"Filtered dataset shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3bf104d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText vocab size: 576768\n"
     ]
    }
   ],
   "source": [
    "fasttext_path = 'embeddings/cc.ne.300.vec'\n",
    "fasttext_model = gensim.models.KeyedVectors.load_word2vec_format(fasttext_path)\n",
    "print(\"FastText vocab size:\", len(fasttext_model.key_to_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7910178e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (4129, 50, 300)\n"
     ]
    }
   ],
   "source": [
    "def embed_comment(comment, max_len=50):\n",
    "    \"\"\"\n",
    "    Convert a comment into a fixed-length embedding matrix.\n",
    "    - Tokenize into words.\n",
    "    - Map each word to FastText vector (300-dim).\n",
    "    - Pad or truncate to max_len tokens.\n",
    "    \"\"\"\n",
    "    tokens = str(comment).strip().split()\n",
    "    vectors = []\n",
    "    for tok in tokens:\n",
    "        if tok in fasttext_model.key_to_index:\n",
    "            vectors.append(fasttext_model[tok])\n",
    "        else:\n",
    "            vectors.append(np.zeros(fasttext_model.vector_size))\n",
    "    # Pad / truncate\n",
    "    if len(vectors) < max_len:\n",
    "        pad = [np.zeros(fasttext_model.vector_size)] * (max_len - len(vectors))\n",
    "        vectors.extend(pad)\n",
    "    else:\n",
    "        vectors = vectors[:max_len]\n",
    "    return np.array(vectors)\n",
    "\n",
    "# Build embeddings\n",
    "X = np.stack([embed_comment(c) for c in df['comment']])\n",
    "print(\"Embeddings shape:\", X.shape)   # (num_samples, max_len, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd45ef8e",
   "metadata": {},
   "source": [
    "## Label Encoding of Output Variables\n",
    "\n",
    "- `LabelEncoder` is a class provided by the **`sklearn.preprocessing`** module.\n",
    "- Two independent `LabelEncoder` objects are created to separately encode **aspect** and **sentiment** labels.\n",
    "- Each encoder learns and stores the unique class labels in the `classes_` attribute.\n",
    "- The categorical labels are transformed into integer values, as machine learning models require numerical inputs.\n",
    "- Label encoding is performed **before one-hot encoding**, since one-hot encoding operates on integer-encoded labels.\n",
    "\n",
    "### Working of `fit_transform()`\n",
    "\n",
    "- `fit_transform()` performs the **fitting** and **transformation** steps in a single operation.\n",
    "\n",
    "#### `fit()`\n",
    "- Identifies all unique class labels in the data\n",
    "- Sorts the labels lexicographically\n",
    "- Stores the sorted labels in `encoder.classes_`\n",
    "- learns so done in the training data\n",
    "- Should not fit() again on validation data **serious bug** \n",
    "\n",
    "1. If fit didnt run then classes_ doesnot exist\n",
    "\n",
    "#### `transform()`\n",
    "- Replaces each categorical label with its corresponding integer index\n",
    "- it doesnot learn anything just replaces the label with integer index only on the validation/test data i.e. already trained ones\n",
    "\n",
    "### Working of 'to_categorical()'\n",
    "- it is from tensorflow.keras.utils\n",
    "- this is **one hot encoding**\n",
    "- it converts integer class labels into probability target vectors that neural network can learn from.\n",
    "\n",
    "#### to_categorical() line of code\n",
    "- this is using the integer labels we just obtained from the fit_transform() and is also calculating the total number of aspects and sentiment labels then applying one hot encoding \n",
    "1. e.g. if y_aspect_int = [2, 0, 1] and num_classes = 4 then\n",
    "\n",
    "y_aspect =\n",
    "[\n",
    " [0, 0, 1, 0],  # governance\n",
    " [1, 0, 0, 0],  # corruption\n",
    " [0, 1, 0, 0]   # economy\n",
    "]\n",
    " this will be the result after the line of code\n",
    "\n",
    "- this is done because the loss function is valid only if y is one hot vector. where y is target i.e. aspect and sentiment are our targets\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03acd2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect classes: ['corruption' 'economy' 'governance' 'policy' 'service']\n",
      "Sentiment classes: ['negative' 'neutral' 'positive']\n"
     ]
    }
   ],
   "source": [
    "aspect_encoder = LabelEncoder()\n",
    "sentiment_encoder = LabelEncoder()\n",
    "\n",
    "y_aspect_int = aspect_encoder.fit_transform(df['aspect'])\n",
    "y_sentiment_int = sentiment_encoder.fit_transform(df['sentiment'])\n",
    "\n",
    "y_aspect = to_categorical(y_aspect_int, num_classes=len(valid_aspects))\n",
    "y_sentiment = to_categorical(y_sentiment_int, num_classes=len(valid_sentiments))\n",
    "\n",
    "print(\"Aspect classes:\", aspect_encoder.classes_)\n",
    "print(\"Sentiment classes:\", sentiment_encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fdcd3f",
   "metadata": {},
   "source": [
    "## StratifiedShuffleSplit\n",
    "\n",
    "- this splits the datasets preserving the class distribution of targets.\n",
    "- it is a object not the split itself.\n",
    "- In this project, datasets are imbalanced as some classes of aspects or sentiment has many datas than other, so to maintain the **same proportion** of each class in both train and test sets we used this.\n",
    "\n",
    "1. Expects **integer class labels** for stratification not the one hot encoding.\n",
    "\n",
    "### Stratify\n",
    "1. It means to split the dataset so that each subset has the same proportion of the classes as the original datasets.\n",
    "2. Essential in multi class classification.\n",
    "\n",
    "### Random_state=42\n",
    "- Its significance is that we can get the same combination of samples and classes in our training and test splits i.e. fixed randomness.\n",
    "\n",
    "### sss.split()\n",
    "- It doesnot care about the number of classes directly. It uses the class labels and returns the index of the samples in X. where X is comment as target is dropped.\n",
    "- Indexes are row number of X\n",
    "- **After getting the indices, we index the one hot encoded arrays of both aspects and sentiment.**\n",
    "\n",
    "### Steps are: \n",
    "1. We group all the index of samples in different arrays according to the integer class labels. e.g. if sample index 1 3 0 has class 3 then they will be grouped together.\n",
    "2. Then we suffle indices with each class as random_state ensures the fixed samples.\n",
    "3. Caluculate the number of train tests samples using the test_size.\n",
    "4. Then split it \n",
    "5. Combine the indices across all classes and train test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0cbdcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (3303, 50, 300)\n",
      "Test set shape: (826, 50, 300)\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_idx, test_idx in sss.split(X, y_aspect_int):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_aspect_train, y_aspect_test = y_aspect[train_idx], y_aspect[test_idx]\n",
    "    y_sent_train, y_sent_test = y_sentiment[train_idx], y_sentiment[test_idx]\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51df069",
   "metadata": {},
   "source": [
    "## About the multi-task CNN-BiLSTM model\n",
    "\n",
    "- We use the Input shape and make it fixed as this is required for models and **batch processing**. \n",
    "- 50 here is the sequence length not necessary the comments max length.\n",
    "\n",
    "### CNN\n",
    "\n",
    "#### 1D convolutional layer\n",
    "- Has 128 different filters or kernels or feature detectors.\n",
    "1. Filter (kernel)\n",
    "   - It is the small matrix of weights that is learned during training.\n",
    "   - So as our input shape is 50 sequence with 300 dimension, this means one comment will have 50 tokens and for each token we will have 300 embeddings and this is fed into the 1d convolutional. there as kernel size is 3 so the filter i.e. matrix selects the 3 consecutive tokens embeddings and then multiply it with the filter and gives the feature map of length = 50-3+1. and this repeats for 128 times and the words now will be other 3 consecutive. due to this it learns the different patterns.\n",
    "\n",
    "- As it has size 3 so it will look at 3 consecutive elements as a time.\n",
    "\n",
    "2. Activation \n",
    "- activation = sum(filter_weights * input_slice) + bias\n",
    "**Activation is high only if the pattern in embeddings matches what the filter has learned.**\n",
    "\n",
    "\n",
    "\n",
    "#### GlobalMaxPooling \n",
    "   - It scans the entire sequence i.e (48,128) and among the different features of the feature map  of individual filter, it selects the maximum value and reduces dimensionality to (128,).\n",
    "\n",
    "   - It is different from MaxPooling1D as this keeps some sequence info whereas the GlobalMaxPooling reduces the entire feature map to 1 number.\n",
    "\n",
    "### BiLSTM\n",
    "\n",
    "- Standard LSTM i.e. special RNN that reads sequence forwards and backward.\n",
    "- Has memory cells and gates to control information flow\n",
    "- Building blocks are: \n",
    "1. Cell state - long term memory\n",
    "2. Hidden state - short term memory\n",
    "3. Gates \n",
    "\n",
    "The type of gates are: \n",
    "1. **Forget gate**\n",
    "2. **Input gate**\n",
    "3. **Output gate**\n",
    "\n",
    "***At each timestep:***\n",
    "Forward: h_t^f = encodes info from past tokens\n",
    "Backward: h_t^b = encodes info from future tokens\n",
    "\n",
    "\n",
    "- The internal task is usually handled by library, we only interact with **units** i.e. the size of hidden state and **return sequences** i.e. whether to ouput the hidden states for all timesteps or just the last one(if false then last only which is default in this code.)\n",
    "\n",
    "\n",
    "1. Timesteps here means each token.\n",
    "\n",
    "**Here BiLSTM and CNN are parallel branches not sequential because after cnn max pooling it only gives the 128 i.e. the compresed level local info due to which BiLSTM looses full token level context so reduces position granularity.**\n",
    "\n",
    "#### Working of BiLSTM \n",
    "- In this there are 50 timesteps as there as 50 tokens in input layer.\n",
    "- At each timestep t i.e. each word, LSTM cell recieves: \n",
    "     1. Current word embedding \n",
    "     2. Previous hidden state\n",
    "     3. Previous cell state\n",
    "- There are 4 steps working in parallel i.e. \n",
    "   1. Forget gate with 128 units works in the one token at one timestep and decides what to keep and which feature to forget i.e. shape (128,)\n",
    "   \n",
    "   2. Input gate also has 128 values and it decides what new infor to write.\n",
    "\n",
    "   3. Cell state update is the vector operation. It updates the 128 memory tracks simultaneously.\n",
    "\n",
    "   4. Output gate == from here **hidden state is passed forward**\n",
    "\n",
    "- Finally it outputs a single 256 dimensional hidden state vector of the last token as the return sequnences is default false.\n",
    "   \n",
    "\n",
    "## About Concatenation\n",
    "- Concatenation is done along the **feature axis** but not by tokens.\n",
    "- Droupout doesnot deactivate the CNN or BiLSTM neurons themselves but they **temporarily removes the contribution of some features to the next layers by setting them to 0**\n",
    "\n",
    "## Dense Layer\n",
    "- It is a separate neural network model which takes the feature from the CNN and BiLSTM and then act as **task specific classifiers**\n",
    "\n",
    "- We have choosen 64 dense layers as this is reasonable and practical for the input of 384 where the weights becomes = 384*64 + biases i.e. 64. These are trainable and wont cause underfit or overfit. so works perfectly in this input.\n",
    "\n",
    "- We used ReLU as this is max(0,x) [0,infinity) here positive is not vanished.\n",
    "\n",
    "- Its input is (384,) and as there is 64 dense layer, the output will be (64,). \n",
    "This is because, each neuron takes all 384 input and for that it calculates the weight * drop for all 384 features and add biases and then pass it to the activation function where ReLU gives a single number ouput. This is for the one neuron and same repeas for other 63 neurons so total output is only (64,)..\n",
    "This is **not the final prediction**\n",
    " \n",
    "This is the input to the final output layer where it contains combination of features usesful for predicting sentiment.\n",
    "\n",
    "## Ouput layer\n",
    "\n",
    "- 3 for sentiment as 3 classes and 5 for abstract\n",
    "\n",
    "### Categorical cross entropy\n",
    "\n",
    "It penalizes the model when predicted probability for the correct class is low.\n",
    "\n",
    "#### Cross entropy measures difference between two probability distribution.\n",
    "- loss = - sum(pi * log(qi))\n",
    "where pi is the true distribution and\n",
    "      qi is the predicted probability after softmax.\n",
    "\n",
    "### Adam Optimizer\n",
    "Adaptive Moment Estimation\n",
    "\n",
    "- Here we gave the starting step size for weight updates but later Adam adjust it.\n",
    "- Has two ideas as **Momentum**, it remembers past gradients and **RMSProp** , it updates by the recent magnitude of gradients.\n",
    "\n",
    "#### Main difference of ADAM with other is that it updates the value of learning rate for each parameter on the basis of past or recent gradients while other updates weights of parameter using the same learning rate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a690c919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">115,328</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">439,296</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooli… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,640</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,640</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sentiment (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ aspect (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m115,328\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m439,296\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_max_pooli… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m24,640\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m24,640\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sentiment (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m195\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ aspect (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │        \u001b[38;5;34m325\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">604,424</span> (2.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m604,424\u001b[0m (2.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">604,424</span> (2.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m604,424\u001b[0m (2.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_layer = Input(shape=(50, 300))\n",
    "\n",
    "# CNN + GlobalMaxPooling\n",
    "conv = Conv1D(filters=128, kernel_size=3, activation='relu')(input_layer)\n",
    "pool = GlobalMaxPooling1D()(conv)\n",
    "\n",
    "# BiLSTM\n",
    "bilstm = Bidirectional(LSTM(128))(input_layer)\n",
    "\n",
    "# Concatenate CNN + BiLSTM features\n",
    "merged = tf.keras.layers.concatenate([pool, bilstm])\n",
    "\n",
    "# Shared dropout\n",
    "drop = Dropout(0.5)(merged)\n",
    "\n",
    "# Task-specific dense layers\n",
    "sentiment_dense = Dense(64, activation='relu')(drop)\n",
    "sentiment_output = Dense(3, activation='softmax', name=\"sentiment\")(sentiment_dense)\n",
    "\n",
    "aspect_dense = Dense(64, activation='relu')(drop)\n",
    "aspect_output = Dense(5, activation='softmax', name=\"aspect\")(aspect_dense)\n",
    "\n",
    "# Build model\n",
    "model = Model(inputs=input_layer, outputs=[sentiment_output, aspect_output])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss={\"sentiment\": \"categorical_crossentropy\", \"aspect\": \"categorical_crossentropy\"},\n",
    "    metrics={\"sentiment\": [\"accuracy\"], \"aspect\": [\"accuracy\"]}\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9595e2d5",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "### Batch Size\n",
    "\n",
    "- Batch size is the number of samples the model processes before updating weights once. It helps the optimizer by controlling the gradient estimate: smaller batches introduce noise, which can improve generalization; larger batches give more accurate gradients, which can speed up convergence. For optimizers like Adam, batch size affects the moving averages of gradients (m_t and v_t), balancing stability and adaptiveness.\n",
    "\n",
    "### Epochs and Early Stopping\n",
    "\n",
    "- **Maximum Epochs**: 50. An epoch is one complete pass through the entire training dataset. The model was set to train for up to 50 epochs.\n",
    "\n",
    "- **Early Stopping**: After each epoch, the model's performance is evaluated on the validation set (the test split). If the validation loss has not improved for 3 consecutive epochs (patience = 3), training stops automatically. Additionally, restore_best_weights=True ensures the final model uses the weights from the epoch with the lowest validation loss, not the last epoch.\n",
    "\n",
    "- **Why Early Stopping matters**: Without it, the model would continue training until epoch 50, likely overfitting. The training loss would keep decreasing but the validation loss would start increasing, meaning the model is memorizing training data rather than learning general patterns. Early stopping prevents this by halting at the optimal point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2962beb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    {\"sentiment\": y_sent_train, \"aspect\": y_aspect_train},\n",
    "    validation_data=(X_test, {\"sentiment\": y_sent_test, \"aspect\": y_aspect_test}),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604b35c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training vs Validation Loss ---\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"training_validation_loss.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "# --- Training vs Validation Accuracy (Sentiment) ---\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(history.history['sentiment_accuracy'], label='Training Sentiment Accuracy')\n",
    "plt.plot(history.history['val_sentiment_accuracy'], label='Validation Sentiment Accuracy')\n",
    "plt.title('Training vs Validation Accuracy (Sentiment)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"training_validation_accuracy.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49278677",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_probs, aspect_probs = model.predict(X_test)\n",
    "\n",
    "y_sent_pred = np.argmax(sentiment_probs, axis=1)\n",
    "y_asp_pred = np.argmax(aspect_probs, axis=1)\n",
    "\n",
    "y_sent_true = np.argmax(y_sent_test, axis=1)\n",
    "y_asp_true = np.argmax(y_aspect_test, axis=1)\n",
    "\n",
    "print(\"=== Sentiment Classification Report ===\")\n",
    "print(classification_report(y_sent_true, y_sent_pred, target_names=sentiment_encoder.classes_))\n",
    "\n",
    "print(\"=== Aspect Classification Report ===\")\n",
    "print(classification_report(y_asp_true, y_asp_pred, target_names=aspect_encoder.classes_))\n",
    "\n",
    "# Confusion Matrices\n",
    "cm_sent = confusion_matrix(y_sent_true, y_sent_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm_sent, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=sentiment_encoder.classes_,\n",
    "            yticklabels=sentiment_encoder.classes_)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Sentiment Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "cm_asp = confusion_matrix(y_asp_true, y_asp_pred)\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.heatmap(cm_asp, annot=True, fmt=\"d\", cmap=\"Greens\",\n",
    "            xticklabels=aspect_encoder.classes_,\n",
    "            yticklabels=aspect_encoder.classes_)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Aspect Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e655213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "# --- Precision-Recall Curves for Sentiment ---\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, class_name in enumerate(sentiment_encoder.classes_):\n",
    "    y_true_bin = (y_sent_true == i).astype(int)\n",
    "    y_score = sentiment_probs[:, i]\n",
    "    precision, recall, _ = precision_recall_curve(y_true_bin, y_score)\n",
    "    ap = average_precision_score(y_true_bin, y_score)\n",
    "    plt.plot(recall, precision, label=f\"{class_name} (AP={ap:.2f})\")\n",
    "\n",
    "plt.title(\"Precision-Recall Curve (Sentiment)\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"precision_recall_sentiment.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# --- Precision-Recall Curves for Aspect ---\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, class_name in enumerate(aspect_encoder.classes_):\n",
    "    y_true_bin = (y_asp_true == i).astype(int)\n",
    "    y_score = aspect_probs[:, i]\n",
    "    precision, recall, _ = precision_recall_curve(y_true_bin, y_score)\n",
    "    ap = average_precision_score(y_true_bin, y_score)\n",
    "    plt.plot(recall, precision, label=f\"{class_name} (AP={ap:.2f})\")\n",
    "\n",
    "plt.title(\"Precision-Recall Curve (Aspect)\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"precision_recall_aspect.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ce5d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "# --- Calibration Curve for Sentiment ---\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, class_name in enumerate(sentiment_encoder.classes_):\n",
    "    y_true_bin = (y_sent_true == i).astype(int)\n",
    "    y_score = sentiment_probs[:, i]\n",
    "    prob_true, prob_pred = calibration_curve(y_true_bin, y_score, n_bins=10)\n",
    "    plt.plot(prob_pred, prob_true, marker='o', label=f\"{class_name}\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')  # perfect calibration line\n",
    "plt.title(\"Calibration Curve (Sentiment)\")\n",
    "plt.xlabel(\"Mean Predicted Probability\")\n",
    "plt.ylabel(\"Fraction of Positives\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# --- Calibration Curve for Aspect ---\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, class_name in enumerate(aspect_encoder.classes_):\n",
    "    y_true_bin = (y_asp_true == i).astype(int)\n",
    "    y_score = aspect_probs[:, i]\n",
    "    prob_true, prob_pred = calibration_curve(y_true_bin, y_score, n_bins=10)\n",
    "    plt.plot(prob_pred, prob_true, marker='o', label=f\"{class_name}\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.title(\"Calibration Curve (Aspect)\")\n",
    "plt.xlabel(\"Mean Predicted Probability\")\n",
    "plt.ylabel(\"Fraction of Positives\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a1b782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# --- ROC Curves for Sentiment ---\n",
    "# Binarize true labels for multi-class ROC\n",
    "y_sent_true_bin = label_binarize(y_sent_true, classes=range(len(sentiment_encoder.classes_)))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, class_name in enumerate(sentiment_encoder.classes_):\n",
    "    fpr, tpr, _ = roc_curve(y_sent_true_bin[:, i], sentiment_probs[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f\"{class_name} (AUC={roc_auc:.2f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')  # diagonal line\n",
    "plt.title(\"ROC Curve (Sentiment)\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"roc_curve_sentiment.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
